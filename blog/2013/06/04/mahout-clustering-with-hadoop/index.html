
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!-->
<html class="no-js" lang="zh-CN"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>在Hadoop上运行Mahout KMeans聚类分析 - Zhou&#39;s Blog</title>
  <meta name="author" content="yoyzhou">
  <!--[if lt IE 9]>
    <script src="http://x.papaapp.com/farm1/a571d2/8dda131d/html5shiv.js"></script>
    <![endif]-->
  
  <meta name="description" content="本文首先介绍了如何配置Mahout的Hadoop的运行环境，然后介绍如何使用mahout kmeans命令行将聚类分析运行在Hadoop上。">
  <meta name="keywords" content="Mahout, Hadoop, Clustering, Data Mining, Machine Learning, Java, MapReduce">

  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://yoyzhou.github.io/blog/2013/06/04/mahout-clustering-with-hadoop/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script type="text/javascript" src="http://t.papaapp.com/js/libs/jquery/1.7.2/jquery.js"></script>
   <link href="/stylesheets/data-table.css" media="screen, projection" rel="stylesheet" type="text/css" />
  <script src="/javascripts/modernizr-2.0.js"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
	      jax: ["input/TeX", "output/HTML-CSS"],
		  tex2jax: {
		  inlineMath: [ ['$', '$'], ["\\(", "\\)"] ],
		  displayMath: [ ['$$', '$$'], ["\\[", "\\]"] ],
		  processEscapes: true,
		  skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
		}}
   );
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>
<script src="/javascripts/ender.js"></script>
<script src="/javascripts/octopress.js" type="text/javascript"></script>
<link href="/atom.xml" rel="alternate" title="Zhou\'s Blog" type="application/atom+xml">

  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-34034666-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  <header id="header" class="clearfix">    <div class="container">
        <div class="col-group">
            <div class="site-name ">
                <a id="logo" href="/">
                   Zhou&#39;s Blog
                </a>
                <p class="description">There is no truth as such, there is only truth from a point of view [Nietzsche]</p>
            </div>
            <div>
                <nav id="nav-menu" class="clearfix">
                    <a class="index-nav current" href="/">Blog</a>
<a class="archives-nav" href="/blog/archives">Archives</a>
                </nav>
            </div>
        </div>
    </div>
</header>
  <div id="body">
    <div class="container">
    	<div class="col-group">
			<div class="col-8" id="main">
  <div class="res-cons">
  <article class="post clearfix">
  
  <header>
    
      <h1 class="post-title">在Hadoop上运行Mahout KMeans聚类分析</h1>
    
    
      <p class="post-meta">
        








  


<time datetime="2013-06-04T20:18:00-07:00" pubdate data-updated="true"></time>
        
         | <a href="#disqus_thread">Comments</a>
        
      </p>
    
  </header>


<div class="post-content"><p>上一篇文章<a href="/blog/2013/05/26/clustering-with-mahout/">“Mahout与聚类分析”</a>介绍了如何使用Mahout进行聚类分析的步骤，并且结合实例使用K-Means对微博名人共同关注数据进行了共被关注聚类分析。Mahout运行有本地运行和Hadoop运行两种模式，本地运行是指在用户本地的单机模式下运行，就像运行其他普通的程序一样，但是这样这样就不能最大限度的发挥出Mahout的优势，在本文中我们介绍如何让我们的Mahout聚类分析程序在Hahoop集群上运行（在实际操作中笔者使用的伪分布Hadoop，而不是真正的Hadoop集群）。</p>

<h4 id="mahout">配置Mahout运行环境</h4>

<p>Mahout运行配置可以在<code>$MAHOUT_HOME/bin/mahout</code>里面进行设置，实际上<code>$MAHOUT_HOME/bin/mahout</code>就是Mahout在命令行的启动脚本，这一点与Hadoop相似，但也又不同，Hadoop在$HADOOP_HOME\conf下面还提供了专门的hadoop-env.sh文件进行相关环境变量的配置，而Mahout在conf目录下没有提供这样的文件。</p>

<h5 id="mahoutlocalhadoopconfdir">MAHOUT_LOCAL与HADOOP_CONF_DIR</h5>

<p>以上的连个参数是控制Mahout是在本地运行还是在Hadoop上运行的关键。</p>

<p><code>$MAHOUT_HOME/bin/mahout</code>文件指出，<strong>只要设置<code>MAHOUT_LOCAL</code>的值为一个非空（not empty string）值，则不管用户有没有设置HADOOP_CONF_DIR和HADOOP_HOME这两个参数，Mahout都以本地模式运行</strong>；换句话说，如果要想Mahout运行在Hadoop上，则MAHOUT_LOCAL必须为空。 </p>

<p><code>HADOOP_CONF_DIR</code>参数指定Mahout运行Hadoop模式时使用的Hadoop配置信息，这个文件目录一般指向的是$HADOOP_HOME目录下的conf目录。</p>

<p>除此之外，我们还应该设置<code>JAVA_HOME</code>或者<code>MAHOUT_JAVA_HOME</code>变量，以及必须将Hadoop的执行文件加入到PATH中。</p>

<p>综上所述：</p>

<p>1. 添加<code>JAVA_HOME</code>变量，可以在直接设置在<code>$MAHOUT_HOME/bin/mahout</code>中，也可以在user/bash profile里面设置(如<code>./bashrc</code>)</p>

<p>2. 设置MAHOUT_HOME并添加Hadoop的执行文件到PATH中</p>

<p>两个步骤在<code>~/.bashrc</code>的设置如下：</p>

<pre><code>export JAVA_HOME=/usr/lib/jvm/java-7-openjdk-i386
#export HADOOP_HOME=/home/yoyzhou/workspace/hadoop-1.1.2
export MAHOUT_HOME=/home/yoyzhou/workspace/mahout-0.7
export PATH=$PATH:/home/yoyzhou/workspace/hadoop-1.1.2/bin:$MAHOUT_HOME/bin
</code></pre>

<p>编辑完<code>~/.bashrc</code>,重启Terminal即可生效。</p>

<p>3. 编辑<code>$MAHOUT_HOME/bin/mahout</code>，将<code>HADOOP_CONF_DIR</code>设置为<code>$HADOOP_HOME\conf</code></p>

<pre><code>HADOOP_CONF_DIR=/home/yoyzhou/workspace/hadoop-1.1.2/conf
</code></pre>

<p>读者可以将相关的Hadoop和Mahout主目录修改自己系统上面的目录地址，设置好之后重启Terminal，在命令行输入mahout，如果你看到如下的信息，就说明Mahout的Hadoop运行模式已经配置好了。</p>

<pre><code>MAHOUT_LOCAL is not set; adding HADOOP_CONF_DIR to classpath. 
Running on hadoop...
</code></pre>

<p>要想使用本地模式运行，只需在<code>$MAHOUT_HOME/bin/mahout</code>添加一条设置<code>MAHOUT_LOCAL</code>为非空的语句即可。</p>

<h4 id="mahout-1">Mahout命令行</h4>

<p>Mahout为相关的数据挖掘算法提供了相应的命令行入口，同时提供了一些数据分析处理的用到的工具集。这些命令可以通过在终端输入<code>mahout</code>获得。以下显示了输入<code>mahout</code>的部分信息：</p>

<pre><code>....
Valid program names are:
  arff.vector: : Generate Vectors from an ARFF file or directory
  baumwelch: : Baum-Welch algorithm for unsupervised HMM training
  canopy: : Canopy clustering
  cat: : Print a file or resource as the logistic regression models would see it
  cleansvd: : Cleanup and verification of SVD output
  clusterdump: : Dump cluster output to text
  ....
  fkmeans: : Fuzzy K-means clustering
  fpg: : Frequent Pattern Growth
  hmmpredict: : Generate random sequence of observations by given HMM
  itemsimilarity: : Compute the item-item-similarities for item-based collaborative filtering
  kmeans: : K-means clustering
....
</code></pre>

<h4 id="mahout-kmeans">Mahout kmeans</h4>

<p>在上一篇<a href="/blog/2013/05/26/clustering-with-mahout/">文章</a>，我们通过调用KMeansDriver.run()方法从Mahout程序中直接启动KMeans算法，这种方式对于在本地调试程序非常有用，但是在真实项目中，无论是使用Hadoop模式运行，还是本地运行，从命令行运行Mahout的相关算法更加合适，这样的好处是我们只需要给Mahout提供符合相应算法要求的输入数据，即可以利用Mahout分布式处理的优势。比如在本例中，使用kmeans算法，只需要事先将数据处理成Mahout kmeans算法要求的输入数据，然后在命令行调用<code>mahout kmeans [options]</code>即可。</p>

<p>在命令行输入不带任何参数的<code>mahout kmeans</code>，Mahout将为你列出在命令行使用kmeans算法的使用方法。</p>

<pre><code>Usage:                                                                          
 [--input &lt;input&gt; --output &lt;output&gt; --distanceMeasure &lt;distanceMeasure&gt;         
--clusters &lt;clusters&gt; --numClusters &lt;k&gt; --convergenceDelta &lt;convergenceDelta&gt;   
--maxIter &lt;maxIter&gt; --overwrite --clustering --method &lt;method&gt;                  
--outlierThreshold &lt;outlierThreshold&gt; --help --tempDir &lt;tempDir&gt; --startPhase   
&lt;startPhase&gt; --endPhase &lt;endPhase&gt;]                                             
--clusters (-c) clusters    The input centroids, as Vectors.  Must be a         
	                        SequenceFile of Writable, Cluster/Canopy.  If k is  
	                        also specified, then a random set of vectors will   
	                        be selected and written out to this path first 
</code></pre>

<p>相关的参数我们已经在上篇<a href="/blog/2013/05/26/clustering-with-mahout/">文章</a>中提到过。</p>

<p>具体的步骤如下：</p>

<pre><code>1. 将数据处理为Mahout向量（Vector）的形式
2. 将Mahout向量转化为Hadoop SequenceFile
3. 创建K个初始质心\[可选\]
4. 将Mahout向量的SequenceFile复制到HDFS上
5. 运行`mahout kmeans [options]`
</code></pre>

<p>下面的命令显示使用CosineDistanceMeasure对data/vectors目录下Mahout向量数据进行kmeans聚类分析，输出结果保存在output目录下。</p>

<pre><code>mahout kmeans -i data/vectors -o output -c data/clusters \
-dm org.apache.mahout.common.distance.CosineDistanceMeasure \
-x 10 -ow -cd 0.001 -cl
</code></pre>

<p>更加详细的命令行参数可以在Mahout wiki <a href="https://cwiki.apache.org/MAHOUT/k-means-commandline.html">k-means-commandline</a>上查找到。</p>

<h4 id="section">总结</h4>

<p>本文首先介绍了如何配置Mahout的Hadoop的运行环境，然后介绍如何使用mahout kmeans命令行将聚类分析运行在Hadoop上。</p>

</div>


  <footer class="post-footer">
    <div class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">yoyzhou</span></span>
 under 

<span class="categories">
  
    <a class='category' href='/blog/categories/clustering/'>clustering</a>, <a class='category' href='/blog/categories/data-mining/'>data mining</a>, <a class='category' href='/blog/categories/hadoop/'>hadoop</a>, <a class='category' href='/blog/categories/mahout/'>mahout</a>
  
</span>


    </div>
    
      <div class="sharing">
  
  
  
</div>

    
    <div class="meta">
      
        <a class="basic-alignment left" href="/blog/2013/05/26/clustering-with-mahout/" title="Previous Post: Mahout与聚类分析">&laquo; Mahout与聚类分析</a>
      
      
    </div>
  </footer>
</article>

  <section>
    <h3>Comments</h3>
    <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
  </section>

  </div>
</div>

  <aside id="secondary">
  
    
<section class="widget">
	<h3 class="widget-title">About Me</h3>
	<p><code style="font-size: 14px;">Writing is the best way of learning</code></p>
</section>
<section class="widget">
	<h3 class="widget-title">Recent Posts</h3>
	<ul class="widget-list">
		
     	<li>
      	  <a href="/blog/2013/06/04/mahout-clustering-with-hadoop/">在Hadoop上运行Mahout KMeans聚类分析</a>
      	</li>
    	
     	<li>
      	  <a href="/blog/2013/05/26/clustering-with-mahout/">Mahout与聚类分析</a>
      	</li>
    	
     	<li>
      	  <a href="/blog/2013/05/13/hadoop-write-ur-own-rawcomparator/">使用RawComparator加速Hadoop程序</a>
      	</li>
    	
     	<li>
      	  <a href="/blog/2013/05/10/hadoop-serialization-and-writable-object-2/">Hadoop序列化与Writable接口(二)</a>
      	</li>
    	
     	<li>
      	  <a href="/blog/2013/05/09/hadoop-serialization-and-writable-object-1/">Hadoop序列化与Writable接口(一)</a>
      	</li>
    	
     	<li>
      	  <a href="/blog/2013/04/29/viz-following-networks-of-weibo-celebrities/">微博名人关注网络的社会网络分析</a>
      	</li>
    	
     	<li>
      	  <a href="/blog/2013/04/29/a-kinda-betweenness-centrality-algorithm/">A Kinda Betweenness Centrality Algorithm</a>
      	</li>
    	
     	<li>
      	  <a href="/blog/2013/04/28/studying-notes-a-set-of-measures-of-centrality-based-on-betweenness/">A Set of Measures of Centrality Based on Betweenness</a>
      	</li>
    	
     	<li>
      	  <a href="/blog/2013/04/21/adding-filter-in-hadoop-mapper-class/">Adding Filter in Hadoop Mapper Class</a>
      	</li>
    	
     	<li>
      	  <a href="/blog/2013/04/14/steps-of-programming-hadoop-with-eclipse/">使用Eclipse开发MapReduce程序的步骤</a>
      	</li>
    	
	</ul>
</section>

<section class="widget">
  <h3>GitHub Repos</h3>
  <ul id="gh_repos" class="widget-list">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  
  <a href="https://github.com/yoyzhou">@yoyzhou</a> on GitHub
  
  <script type="text/javascript">
    $.domReady(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'yoyzhou',
            count: 0,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>





  
</aside>


      	</div>
    </div>
  </div>
  <footer id="footer">
  	<div class="container">
	Copyright &copy; 2014 - yoyzhou -
  <span class="credit">Powered by <a rel="nofollow" href="http://octopress.org">Octopress</a> on <a rel="nofollow" href="http://pages.github.com/">GitHubPages</a>
  </span>
  - <span class="credit">Theme by <a rel="nofollow" href="https://github.com/yoyzhou/mewpassant">mewpassant</a></span>


</div>

  </footer>
  

<script type="text/javascript">
      var disqus_shortname = 'yoyzhou';
      
        
        // var disqus_developer = 1;
        var disqus_identifier = 'http://yoyzhou.github.io/blog/2013/06/04/mahout-clustering-with-hadoop/';
        var disqus_url = 'http://yoyzhou.github.io/blog/2013/06/04/mahout-clustering-with-hadoop/';
        var disqus_script = 'embed.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>











</body>
</html>
